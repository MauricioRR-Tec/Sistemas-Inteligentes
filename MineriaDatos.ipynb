{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Viaje a la ciencia de datos - Minería</center></h2>\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"https://lh3.googleusercontent.com/proxy/unyiAlWkrtIY0P6xaDNq4g-pMMNujaZkuwx8mUpDzPwkd1N6DvzkNabDBCyXu7pwnIOB7GoKCZQa7WrpqkceqEtCGiOtVQdxODHWvB2XRQNIiCTOfg53mTuJhMi-rg\"/>\n",
    "\n",
    "Dada la cantidad de datos que aumentan cada segundo que pasa, las personas gravitan cada vez más hacia la ciencia de datos y el aprendizaje automático. Para ser bueno en ellos, es necesario contar con sólidos fundamentos en el dominio de la minería de datos.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "La comprensión de la ciencia de datos proviene de comprender qué son los datos conceptualmente, cómo manejar los datos que recibimos (los datos siempre serán diferentes para cada problema) y cómo preprocesar de manera eficiente los datos antes de entregarlos a los algoritmos de aprendizaje automático."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué son los datos?\n",
    "\n",
    "En términos más simples, los datos son una colección de objetos y sus atributos. Otros nombres para un objeto de datos son registro, punto, vector, patrón, evento, caso, muestra, observación o entidad.\n",
    "\n",
    "---\n",
    "\n",
    "Ahora, debemos saber qué son los atributos.\n",
    "\n",
    "Es una propiedad o característica de un objeto. Ejemplo: color de ojos de una persona. Esto también se conoce con otros nombres como variable, campo, característica, dimensión, etc.\n",
    "\n",
    "Sin embargo, para discutir y analizar con mayor precisión las características de los objetos, les asignamos números o símbolos. Para hacer esto de una manera bien definida, necesitamos una escala de medición. Ahora bien, ¿qué diablos es una escala de medición?\n",
    "\n",
    "Bueno, es una regla (función) que asocia un valor numérico o simbólico (valores de atributo) con un atributo de un objeto. Por ejemplo, clasificamos a alguien como hombre o mujer.\n",
    "\n",
    "![img](https://miro.medium.com/max/1776/1*HKOwwQC_VRb7hCuLKUXwJA.png)\n",
    "\n",
    "---\n",
    "\n",
    "![img](https://miro.medium.com/max/2156/1*tZhUHO2Y0qdcQEoxoHjVnA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los atributos **nominales** y **ordinales** se denominan colectivamente atributos categóricos o cualitativos. \n",
    "\n",
    "Como sugiere el nombre, los atributos cualitativos carecen de la mayoría de las propiedades de los números. Incluso si están representados por números, es decir, enteros, deberían tratarse más como símbolos.\n",
    "\n",
    "Los dos tipos restantes de atributos, **intervalo** y **razón**, se denominan colectivamente atributos cuantitativos o numéricos. Los atributos cuantitativos están representados por números y tienen la mayoría de las propiedades de los números. Tenga en cuenta que los atributos cuantitativos pueden tener valores enteros o ser continuos.\n",
    "\n",
    "Los diferentes tipos de atributos se adhieren a las diferentes propiedades mencionadas anteriormente. Nominal se adhiere a la distinción. Ordinal se adhiere a la distinción y al orden. Interval se adhiere a la distinción, el orden y la diferencia significativa. La proporción se adhiere a las cuatro propiedades (distinción, orden, suma y multiplicación).\n",
    "\n",
    "---\n",
    "\n",
    "![img](https://miro.medium.com/max/688/1*D4CnEgf0NBBU5euOnGWgNg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay tres características generales de los conjuntos de datos: dimensionalidad, dispersión y resolución.\n",
    "\n",
    "---\n",
    "\n",
    "<h3><center>¿Qué es la dimensionalidad?</center></h3>\n",
    "La dimensionalidad de un conjunto de datos es el número de atributos que tienen los objetos.\n",
    "En un conjunto de datos en particular, si hay un gran número de atributos (también llamado alta dimensionalidad), puede resultar difícil analizar dicho conjunto de datos. Cuando se enfrenta este problema, se le llama Maldición de dimensionalidad.\n",
    "Para entender qué diablos es esta Maldición de la dimensionalidad, primero debemos comprender las otras dos características de los datos.\n",
    "\n",
    "---\n",
    "\n",
    "<h3><center>¿Qué es la escasez?</center></h3>\n",
    "\n",
    "Para algunos conjuntos de datos, como aquellos con características asimétricas, la mayoría de los atributos de un objeto tienen valores de 0; en muchos casos, menos del 1% de las entradas son distintas de cero. Estos datos se denominan datos dispersos o se puede decir que el conjunto de datos tiene dispersión.\n",
    "\n",
    "---\n",
    "\n",
    "<h3><center>¿Qué es la resolución?</center></h3>\n",
    "Los patrones en los datos dependen del nivel de resolución. Si la resolución es demasiado fina, es posible que un patrón no sea visible o que esté oculto por el ruido; si la resolución es demasiado gruesa, el patrón puede desaparecer. Por ejemplo, las variaciones de la presión atmosférica en una escala de horas reflejan el movimiento de las tormentas y otros sistemas meteorológicos. En una escala de meses, tales fenómenos no son detectables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, volviendo a la **maldición de la dimensionalidad**, significa que muchos tipos de análisis de datos se vuelven difíciles a medida que aumenta la dimensionalidad (número de atributos en el conjunto de datos) del conjunto de datos. \n",
    "\n",
    "Específicamente, a medida que aumenta la dimensionalidad, los datos se vuelven cada vez más escasos en el espacio que ocupa. \n",
    "\n",
    "Para la **clasificación**, esto puede significar que no hay suficientes objetos de datos para permitir la creación de un modelo que asigne de manera confiable una clase a todos los objetos posibles. Para la **agrupación**, las definiciones de densidad y la distancia entre puntos, que son fundamentales para la agrupación, se vuelven menos significativas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, en cuanto a los tipos de conjuntos de datos, los definimos en tres categorías, a saber, datos de registro, datos basados en gráficos y datos ordenados. Echemos un vistazo a ellos uno a la vez.\n",
    "\n",
    "![img](https://miro.medium.com/max/1000/1*yYV016vKIBM_R2iSNaLufQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://miro.medium.com/max/1000/1*7bFifqQEKKLCfbJFVmEYgQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://miro.medium.com/max/1000/1*yVFaD-VveR8n2FmkKP7i0A.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "-----------\n",
    "\n",
    "<h2><center>Pre procesamiento de Datos</center></h2>\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"https://thumbs.dreamstime.com/z/craftsman-carving-wood-thai-art-69708534.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El preprocesamiento de datos se refiere a los pasos aplicados para hacer que los datos sean más adecuados para la minería de datos. Los pasos utilizados para el preprocesamiento de datos generalmente se dividen en dos categorías:\n",
    "\n",
    "* seleccionar objetos de datos y atributos para el análisis.\n",
    "* creando / cambiando los atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np # used for handling numbers\n",
    "import pandas as pd # used for handling the dataset\n",
    "from sklearn.impute import SimpleImputer # used for handling missing data\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # used for encoding categorical data\n",
    "from sklearn.model_selection import train_test_split # used for splitting training and testing data\n",
    "from sklearn.preprocessing import StandardScaler # used for feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('https://raw.githubusercontent.com/tarunlnmiit/machine_learning/master/DataPreprocessing.csv') # to import the dataset into a variable\n",
    "# Splitting the attributes into independent and dependent attributes\n",
    "X = dataset.iloc[:, :-1].values # attributes to determine dependent variable / Class\n",
    "Y = dataset.iloc[:, -1].values # dependent variable / Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Online Shopper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>49.0</td>\n",
       "      <td>86400.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>32.0</td>\n",
       "      <td>57600.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USA</td>\n",
       "      <td>35.0</td>\n",
       "      <td>64800.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>43.0</td>\n",
       "      <td>73200.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India</td>\n",
       "      <td>40.0</td>\n",
       "      <td>69600.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62400.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>India</td>\n",
       "      <td>53.0</td>\n",
       "      <td>94800.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>USA</td>\n",
       "      <td>55.0</td>\n",
       "      <td>99600.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>India</td>\n",
       "      <td>42.0</td>\n",
       "      <td>80400.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Region   Age   Income Online Shopper\n",
       "0   India  49.0  86400.0             No\n",
       "1  Brazil  32.0  57600.0            Yes\n",
       "2     USA  35.0  64800.0             No\n",
       "3  Brazil  43.0  73200.0             No\n",
       "4     USA  45.0      NaN            Yes\n",
       "5   India  40.0  69600.0            Yes\n",
       "6  Brazil   NaN  62400.0             No\n",
       "7   India  53.0  94800.0            Yes\n",
       "8     USA  55.0  99600.0             No\n",
       "9   India  42.0  80400.0            Yes"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['India', 49.0, 86400.0],\n",
       "       ['Brazil', 32.0, 57600.0],\n",
       "       ['USA', 35.0, 64800.0],\n",
       "       ['Brazil', 43.0, 73200.0],\n",
       "       ['USA', 45.0, nan],\n",
       "       ['India', 40.0, 69600.0],\n",
       "       ['Brazil', nan, 62400.0],\n",
       "       ['India', 53.0, 94800.0],\n",
       "       ['USA', 55.0, 99600.0],\n",
       "       ['India', 42.0, 80400.0]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling the missing data and replace missing values with nan from numpy and replace with mean of all the other values\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean') \n",
    "imputer = imputer.fit(X[:, 1:])\n",
    "X[:, 1:] = imputer.transform(X[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['India', 49.0, 86400.0],\n",
       "       ['Brazil', 32.0, 57600.0],\n",
       "       ['USA', 35.0, 64800.0],\n",
       "       ['Brazil', 43.0, 73200.0],\n",
       "       ['USA', 45.0, 76533.33333333333],\n",
       "       ['India', 40.0, 69600.0],\n",
       "       ['Brazil', 43.77777777777778, 62400.0],\n",
       "       ['India', 53.0, 94800.0],\n",
       "       ['USA', 55.0, 99600.0],\n",
       "       ['India', 42.0, 80400.0]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])\n",
    "\n",
    "onehotencoder = OneHotEncoder()\n",
    "\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "labelencoder_Y = LabelEncoder()\n",
    "Y = labelencoder_Y.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into training set and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
